<p align="center">
  <a href="https://github.com/adacienciala/Salvador">
    <img src="https://user-images.githubusercontent.com/57063056/114593207-1d8bfc80-9c8c-11eb-9c30-75b7377f9e14.png" alt="Logo" width="400">
  </a>

  <h1 align="center">Salvador</h3>

  <p align="center">
    AI powered pictures' generator
  </p>
  
  <p align="center">
    <img src="https://user-images.githubusercontent.com/57063056/114624815-8df94480-9cb1-11eb-8429-3d57fb6fbb84.png" alt="generated image 1" width="128">
    <img src="https://user-images.githubusercontent.com/57063056/114624817-8e91db00-9cb1-11eb-9697-4f82d0584c82.png" alt="generated image 2" width="128">
    <img src="https://user-images.githubusercontent.com/57063056/114624818-8e91db00-9cb1-11eb-8d3d-2d19529c9dd9.png" alt="generated image 3" width="128">
  </p>

</p>

## Table of contents
- [About the project](#about-the-project)
- [Website](#website)
  * [HTTP address](#http-address)
  * [Content](#content)
  * [Technologies](#technologies)
  * [Problems](#problems)
- [Model](#model)
  * [Description](#description)
  * [Generator](#generator)
  * [Discriminator](#discriminator)
  * [Technologies](#technologies-1)
  * [Problems](#problems-1)
- [Database](#database)
- [Authors](#authors)

## About the project

Salvador is a service that provides unique pictures with a single click. Made from scratch, the project involved building a carefully designed DCGAN model capable of generating pictures of landscapes and designing a website to show the results with VanillaJS.

Motivation behind the idea was to understand Deep Learning and its possibilities in the field strictly linked with humans' capability to create art. 

## Website

### HTTP address

The website can be accessed here:

<p align="center">
  <img src="https://user-images.githubusercontent.com/57063056/114598017-b5401980-9c91-11eb-93a9-fb4d31812e2e.png" alt="Website view 1" width="700">
  <br />
  https://adacienciala.github.io/Salvador
</p>

### Content

The flow of the site consists of 4 views:
1. The starting page
2. The generating page 
3. The loading page 
4. The result page

In the background a slider can be seen. It displayes samples of landscapes generated by the model.

<p align="center">
  <img src="https://user-images.githubusercontent.com/57063056/114598017-b5401980-9c91-11eb-93a9-fb4d31812e2e.png" alt="Website view 1" width="400">
  <img src="https://user-images.githubusercontent.com/57063056/114598018-b5401980-9c91-11eb-826d-d758bc01ee3e.png" alt="Website view 2" width="400">
  <img src="https://user-images.githubusercontent.com/57063056/114598021-b5d8b000-9c91-11eb-8e85-9e5a29fa0eeb.png" alt="Website view 3" width="400">
  <img src="https://user-images.githubusercontent.com/57063056/114598024-b5d8b000-9c91-11eb-8726-c9c1e3971ba8.png" alt="Website view 4" width="400">
</p>

### Technologies

* [HTML](https://developer.mozilla.org/en-US/docs/Web/HTML)
* [CSS](https://developer.mozilla.org/en-US/docs/Web/CSS)
* [JavaScript](https://developer.mozilla.org/en-US/docs/Web/JavaScript)
* [JQuery](https://jquery.com/)
* [Flask](https://flask.palletsprojects.com/en/1.1.x/)
* [Github Pages](https://pages.github.com/)
* [Heroku](https://www.heroku.com/)
* [Figma](https://www.figma.com/)

The website was designed with pure HTML, CSS and VanillaJS. The domain was acquired from Github Pages and the server was deployed on the Heroku platform. For the communication and handling requests, Flask and JQuery were used. The design process was conducted in Figma and was hugely carried with *"tinker the CSS and hope for the best"* approach.

### Problems

As the website uses a free hosting, the features had to be strongly cut down for the application **not** to crash. Thus *no option to upscale the images or vectorize* them. Unfortunately, even with only the basic feature of generating the images, the limit allows for *one at a time client handling*. After some idle time, Heroku also changes the application state to "down", so for it to work, the first attempt requires a lot of starting time (minutes). After that, the picture should be generated within 30s - if not, refresh of the page is advised.

## Model

### Description

Neural network model behind Salvador is based on a GAN architecture, more precisely DCGAN (Deep Convolutional
Generative Adversarial Network). It is made of two neural networks - a **generator** responsible for generating pictures and a **discriminator** deciding, if the sample was "real" (from the dataset) or "fake" (generated by the model). 

<p align="center">
  <img src="https://user-images.githubusercontent.com/57063056/114624126-84231180-9cb0-11eb-8422-d0b3e6af9d61.png" alt="DCGAN explained" width="600">
</p>

### Generator

The structure of the generator is made up of:
* dense input layer
* three convolution transposed layers
* convolution output layer

The layers have LeakyReLU activation function on them, with the output layer having a hyperbolic tangent function.

<p align="center">
  <img src="https://user-images.githubusercontent.com/57063056/114598028-b6714680-9c91-11eb-9ae4-d0abc279d289.png" alt="generator architecture" width="700">
</p>

### Discriminator

The structure of the discriminator is made up of:
* four convolution layers
* dense output layer

The layers have a LeakyReLU activation function on them, with the output layer having a sigmoid function.

<p align="center">
  <img src="https://user-images.githubusercontent.com/57063056/114598030-b709dd00-9c91-11eb-8e08-360c44d5113c.png" alt="discriminator architecture" width="700">
</p>

### Technologies

* [Python](https://www.python.org/)
* [Keras](https://keras.io/)
* [Tensorflow](https://www.tensorflow.org/)
* [NumPy](https://numpy.org/)
* [OpenCV](https://opencv.org/)
* [Scikit-learn](https://scikit-learn.org/)
* [Pillow](https://pillow.readthedocs.io/)
* [Matplotlib](https://matplotlib.org/)
* [Selenium](https://www.selenium.dev/)

All the work was done using Python language and its most popular libraries. The Keras and Tensorflow libraries were used for building the models and a Selenium framework for the webscrapper.

### Problems

1. **Loss value**. ALthough the model produces good results, the loss value never fully converges. The interesting part is that although the value is closest after 150 epochs, the best pictures are generated around 650 epochs. The reason behind this behaviour is still unknown.

<p align="center">
  <img src="https://user-images.githubusercontent.com/57063056/114598032-b7a27380-9c91-11eb-9437-4182a00a9763.png" alt="loss value" width="700">
</p>

2. **Database**. Custom webscrapper was prepared for the project but finally the database consisted of 4319 pictures. Although there was already found a bigger database (20k pictures), it was not implemented into the project. The generated pictures don't repeat themselves, but there is a limited variety of the landscapes.

3. **Resolution**. The images now are generated in a 128x128 resolution. OpenCV models were tested and ready to be implemented. From 4 tested models (SRGAN, FSRCNN, EDSR, LapSRN) the EDSR one was getting the best performance. Because of the limitations of the hosting platform, the feature couldn't be implemented despite the efforst put into the process. 

<p align="center">
  <img src="https://user-images.githubusercontent.com/57063056/114598009-b3765600-9c91-11eb-84fc-5a9c7d120846.png" alt="upscaling process" width="700">
</p>

4. **Vectorization**. At the beggining, the pictures were supposed to be vector art images. There were already prepared clustering and quantizationing scripts. Once again, because of the limitations of the hosting platform, the feature couldn't be implemented. With a great sorrow, the work and research on this part was halted.

<p align="center">
  <img src="https://user-images.githubusercontent.com/57063056/114598013-b40eec80-9c91-11eb-91de-1eaeec31fe40.png" alt="vectorization process" width="700">
</p>

## Database

The database used in training the model was acquired from [here](https://www.kaggle.com/arnaud58/landscape-pictures). It's 4319 pictures of landscapes researched from the website [flickr](https://www.flickr.com/) with some repetitive ones.

Those researches were:
- landscapes (900 pictures)
- landscapes montain (900 pictures)
- landscapes desert (100 pictures)
- landscapes sea (500 pictures)
- landscapes beach (500 pictures)
- landscapes island (500 pictures)
- landscapes japan (900 pictures)

## Authors

Adrianna Cieńciała ([@adacienciala](https://github.com/adacienciala)) was responsible for:
- upscaling and vectorizing images
- designing the website and the logo
- building the model
- building the website

Oskar Mikus ([@TinyRogue](https://github.com/TinyRogue)) was responsible for:
- web scraping the database
- organizing the teamwork
- building the model
- building the website
